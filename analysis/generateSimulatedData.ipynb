{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8018a6ba-e78e-493b-9df5-9b8b13428272",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4835c03-9986-4393-811e-2851527fa365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vcf\n",
    "\n",
    "def vcf_to_bed(vcf_path, bed_path):\n",
    "    # Open VCF file\n",
    "    vcf_reader = vcf.Reader(open(vcf_path, 'r'))\n",
    "\n",
    "    # Open BED file for writing\n",
    "    with open(bed_path, 'w') as bed_file:\n",
    "        # Iterate through VCF records and write to BED file\n",
    "        for record in vcf_reader:\n",
    "            chrom = record.CHROM\n",
    "            start = record.POS - 1  # Convert to 0-based coordinates for BED format\n",
    "            end = record.POS\n",
    "            info = record.INFO\n",
    "\n",
    "            bed_file.write(f\"{chrom}\\t{start}\\t{end}\\t{info}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2187776a-b5b5-49a6-be5a-d53838d6d4f4",
   "metadata": {},
   "source": [
    "# Remove Spikes from BAM File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa891b36-462a-48cf-8d4e-d961634c3e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def remove_spikes(input_bam, bed_file, output_bam):\n",
    "    command = [\n",
    "        'samtools',\n",
    "        'view',\n",
    "        '-b',\n",
    "        '-L',\n",
    "        bed_file,\n",
    "        '-o',\n",
    "        output_bam,\n",
    "        input_bam\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        subprocess.run(command, check=True)\n",
    "        print(f\"Spikes removed successfully. Output saved to {output_bam}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "def extract_regions(input_bam, bed_file, output_bam):\n",
    "    # Step 2: Extract regions from the first BAM file\n",
    "    with pysam.AlignmentFile(input_bam, \"rb\") as bam_file:\n",
    "        regions = pysam.TabixFile(bed_file)\n",
    "        extracted_reads = [read for read in bam_file.fetch() if regions.fetch(read.reference_name, read.reference_start, read.reference_end)]\n",
    "\n",
    "    # Write the extracted reads to a new BAM file\n",
    "    with pysam.AlignmentFile(output_bam, \"wb\", header=bam_file.header) as output_bam_file:\n",
    "        for read in extracted_reads:\n",
    "            output_bam_file.write(read)\n",
    "\n",
    "def simulate_insertions(reference_genome, extracted_bam, output_prefix):\n",
    "    # Step 3: Simulate insertion reads using ART\n",
    "    command = [\n",
    "        'art_illumina',\n",
    "        '-ss', 'HS25',\n",
    "        '-sam',\n",
    "        '-i', extracted_bam,\n",
    "        '-l', '150',\n",
    "        '-f', '50',\n",
    "        '-o', output_prefix,\n",
    "        '-na'  # Disable random read generation to use the input reads\n",
    "    ]\n",
    "    subprocess.run(command, check=True)\n",
    "\n",
    "def merge_bams(original_bam, simulated_bam, merged_bam):\n",
    "    # Step 4: Merge BAM files\n",
    "    with pysam.AlignmentFile(original_bam, \"rb\") as original_file, \\\n",
    "         pysam.AlignmentFile(simulated_bam + '.sam', \"rb\") as simulated_file, \\\n",
    "         pysam.AlignmentFile(merged_bam, \"wb\", header=original_file.header) as output_bam:\n",
    "        for read in original_file:\n",
    "            output_bam.write(read)\n",
    "        for read in simulated_file:\n",
    "            output_bam.write(read)\n",
    "\n",
    "    # Step 5: Sort and index merged BAM file\n",
    "    pysam.sort('-o', merged_bam.replace('.bam', '_sorted.bam'), merged_bam)\n",
    "    pysam.index(merged_bam.replace('.bam', '_sorted.bam'))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify file paths\n",
    "    input_bam = \"/path/to/your/original.bam\"\n",
    "    bed_file = \"/path/to/your/simulated_insertions.bed\"\n",
    "    output_bam = \"/path/to/your/extracted_reads.bam\"\n",
    "    reference_genome = \"/path/to/your/reference_genome.fasta\"\n",
    "    output_prefix = \"/path/to/your/simulated_insertions\"\n",
    "    merged_bam = \"/path/to/your/final_merged.bam\"\n",
    "\n",
    "    # Extract regions from the original BAM file\n",
    "    extract_regions(input_bam, bed_file, output_bam)\n",
    "\n",
    "    # Simulate insertions\n",
    "    simulate_insertions(reference_genome, output_bam, output_prefix)\n",
    "\n",
    "    # Merge the original and simulated BAM files\n",
    "    merge_bams(input_bam, output_prefix + '.bam', merged_bam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
