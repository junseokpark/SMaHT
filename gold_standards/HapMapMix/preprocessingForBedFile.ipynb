{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Alu_concat_tier1.txt\n",
      "Save file: Alu/HG002-tier1.bed (count:1188)\n",
      "Save file: Alu/HG005-tier1.bed (count:1196)\n",
      "Save file: Alu/HG00438-tier1.bed (count:1220)\n",
      "Save file: Alu/HG02257-tier1.bed (count:1520)\n",
      "Save file: Alu/HG02486-tier1.bed (count:1458)\n",
      "Save file: Alu/HG02622-tier1.bed (count:1539)\n",
      "Processing file: Alu_concat_tier2.txt\n",
      "Save file: Alu/HG002-tier2.bed (count:1083)\n",
      "Save file: Alu/HG005-tier2.bed (count:1086)\n",
      "Save file: Alu/HG00438-tier2.bed (count:1101)\n",
      "Save file: Alu/HG02257-tier2.bed (count:1405)\n",
      "Save file: Alu/HG02486-tier2.bed (count:1347)\n",
      "Save file: Alu/HG02622-tier2.bed (count:1422)\n",
      "Processing file: Alu_concat_tier3.txt\n",
      "Save file: Alu/HG002-tier3.bed (count:1015)\n",
      "Save file: Alu/HG005-tier3.bed (count:1008)\n",
      "Save file: Alu/HG00438-tier3.bed (count:1016)\n",
      "Save file: Alu/HG02257-tier3.bed (count:1321)\n",
      "Save file: Alu/HG02486-tier3.bed (count:1257)\n",
      "Save file: Alu/HG02622-tier3.bed (count:1319)\n",
      "Processing file: L1_concat_tier1.txt\n",
      "Save file: L1/HG002-tier1.bed (count:233)\n",
      "Save file: L1/HG005-tier1.bed (count:253)\n",
      "Save file: L1/HG00438-tier1.bed (count:267)\n",
      "Save file: L1/HG02257-tier1.bed (count:286)\n",
      "Save file: L1/HG02486-tier1.bed (count:333)\n",
      "Save file: L1/HG02622-tier1.bed (count:320)\n",
      "Processing file: L1_concat_tier2.txt\n",
      "Save file: L1/HG002-tier2.bed (count:189)\n",
      "Save file: L1/HG005-tier2.bed (count:197)\n",
      "Save file: L1/HG00438-tier2.bed (count:201)\n",
      "Save file: L1/HG02257-tier2.bed (count:225)\n",
      "Save file: L1/HG02486-tier2.bed (count:274)\n",
      "Save file: L1/HG02622-tier2.bed (count:257)\n",
      "Processing file: L1_concat_tier3.txt\n",
      "Save file: L1/HG002-tier3.bed (count:151)\n",
      "Save file: L1/HG005-tier3.bed (count:160)\n",
      "Save file: L1/HG00438-tier3.bed (count:160)\n",
      "Save file: L1/HG02257-tier3.bed (count:191)\n",
      "Save file: L1/HG02486-tier3.bed (count:226)\n",
      "Save file: L1/HG02622-tier3.bed (count:213)\n"
     ]
    }
   ],
   "source": [
    "teClasses = ['Alu', 'L1']\n",
    "tiers = [1, 2, 3]\n",
    "logFileName = \"readme.txt\"\n",
    "\n",
    "\n",
    "def convertResultToBedFile(df, saveFileNameWithDir):\n",
    "    temp = df\n",
    "    temp['position'] = temp['position'].astype(int)\n",
    "    temp['position2'] = temp['position'] +1 \n",
    "    temp['name'] = '.'\n",
    "    temp['score'] = None\n",
    "\n",
    "    temp = temp\n",
    "    temp = temp[['chrom','position','position2','class','score','family']]\n",
    "\n",
    "    temp.to_csv(saveFileNameWithDir, sep='\\t', index=False, header=False)\n",
    "\n",
    "# If the save file already exists, remove it\n",
    "if os.path.exists(logFileName):\n",
    "    os.remove(logFileName)\n",
    "    \n",
    "def writeLog(fileName,log):\n",
    "    print(log)\n",
    "    with open(fileName, 'a') as log_file:\n",
    "        log_file.write(log+\"\\n\")\n",
    "\n",
    "\n",
    "for teClass in teClasses:\n",
    "    for tier in tiers:\n",
    "        fileName = teClass+\"_concat_tier\"+str(tier)+\".txt\"\n",
    "        \n",
    "        writeLog(logFileName, \"Processing file: \"+ fileName)\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(teClass,fileName), delimiter=\"\\t\", )\n",
    "        \n",
    "        # Columns that start with 'HG'\n",
    "        hg_columns = [col for col in df.columns if col.startswith('HG')]\n",
    "\n",
    "        # Create separate dataframes for each HG column\n",
    "        hg_dataframes = {}\n",
    "        for col in hg_columns:\n",
    "            # Filter rows where the HG column is not '.'\n",
    "            filtered_df = df[df[col] != '.'].copy()\n",
    "            # Split the column into 'chrom' and 'pos' based on the HG column's values\n",
    "            filtered_df[['chrom', 'position']] = filtered_df[col].str.split('_', expand=True)\n",
    "            # Convert 'pos' to integer\n",
    "            filtered_df['position'] = filtered_df['position'].astype(int)\n",
    "            # Keep only 'chrom' and 'pos' columns\n",
    "            filtered_df = filtered_df[['chrom', 'position']]\n",
    "            # Save filtered_df\n",
    "            filtered_df['class']=teClass\n",
    "            filtered_df['family']=\".\"\n",
    "\n",
    "            saveFileName = os.path.join(teClass,col+\"-tier\"+str(tier)+\".bed\")\n",
    "            \n",
    "            writeLog(logFileName, \"Save file: \"+ saveFileName + \" (count:\" + str(len(filtered_df)) + \")\")\n",
    "            convertResultToBedFile(filtered_df, saveFileName)\n",
    "            \n",
    "            \n",
    "            hg_dataframes[col] = filtered_df\n",
    "                    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMaHT-3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
